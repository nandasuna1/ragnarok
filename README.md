# ‚úàÔ∏è Ragnarok: Sistema RAG para Incidentes A√©reos da NTSB

Este projeto implementa uma solu√ß√£o de **Retrieval-Augmented Generation (RAG)** para responder perguntas com base nos relat√≥rios da **NTSB (National Transportation Safety Board)** sobre incidentes e acidentes a√©reos nos Estados Unidos.

> Desenvolvido como atividade da disciplina de Minera√ß√£o de Texto

## üîç Vis√£o Geral

**Retrieval-Augmented Generation (RAG)** √© uma abordagem que combina recupera√ß√£o de informa√ß√µes (IR) com gera√ß√£o de linguagem natural (NLG). Nosso sistema utiliza:

- **BM25** (via `rank_bm25`) para buscar documentos relevantes.
- **flan-t5-base** da Hugging Face para gerar respostas baseadas nos documentos.

## ü§ñ Como Usar

1. Clone o reposit√≥rio do git

2. Crie um ambiente virtual (opcional)

```
python -m venv .venv
.venv\Scripts\activate  # Windows
```

3. Instale as dependencias

```
pip install -r requirements.txt
```

4. execute a aplica√ß√£o

```
python app.py
```

A interface Gradio ser√° aberta em http://127.0.0.1:7860.

Exemplo de pergunta

## üß± Arquitetura da Solu√ß√£o

A solu√ß√£o foi estruturada em **tr√™s etapas principais**, seguindo o fluxo de um sistema RAG cl√°ssico:

### 1. **Preprocessamento e Tratamento dos Dados**

- Os dados foram carregados de um arquivo `.csv` com os relat√≥rios da NTSB.
- Realizou-se a limpeza textual e a unifica√ß√£o de campos relevantes (como `date`, `location`, `probable_cause`, etc.) em um campo `document`.
- Os documentos foram transformados para letras min√∫sculas e tokenizados com `nltk.word_tokenize`.

### 2. **Recupera√ß√£o de Documentos com BM25**

- Foi utilizado o modelo **BM25Okapi** da biblioteca `rank_bm25` para indexar os documentos.
- Uma fun√ß√£o `recuperar_documentos(pergunta, bm25, corpus)` retorna os documentos mais relevantes (top-3) com base na similaridade da pergunta com os tokens dos documentos.

### 3. **Gera√ß√£o de Resposta com LLM**

- A gera√ß√£o da resposta √© feita com o modelo `flan-t5-base` da Hugging Face (`transformers`).
- A fun√ß√£o `gerar_resposta(pergunta, documentos)` monta um prompt contendo os documentos relevantes e a pergunta, e o envia ao modelo para gerar uma resposta textual.
- A gera√ß√£o √© controlada por `max_tokens` para respeitar o limite de entrada do modelo.

### 4. **Interface com Gradio**

- Uma interface simples com `Gradio` permite testar o sistema com perguntas personalizadas.
- A interface exibe:

  - Pergunta do usu√°rio
  - Resposta gerada pelo modelo

## ‚ö†Ô∏è Dificuldades Enfrentadas

- **Depend√™ncias do NLTK:** O m√≥dulo `punkt` apresentou problemas de localiza√ß√£o ao usar `venv`, sendo necess√°rio reinstalar manualmente os recursos e ajustar os caminhos.
- **Limite de tokens do modelo:** O `flan-t5-base` tem um limite de entrada, ent√£o em perguntas mais amplas ou com documentos longos, parte do contexto pode ser truncada.
- **Formatos dos documentos:** Alguns documentos da NTSB s√£o mal formatados ou cont√™m valores nulos em campos importantes, o que exigiu cuidados na concatena√ß√£o.

## üìå Limita√ß√µes da Solu√ß√£o

- O modelo n√£o tem conhecimento factual externo, ele apenas "imita" uma resposta com base nos documentos fornecidos.
- O sistema n√£o realiza **verifica√ß√£o de consist√™ncia** entre a resposta gerada e os documentos (ex: pode gerar uma resposta plaus√≠vel mas n√£o textual do documento).
- N√£o h√° suporte a m√∫ltiplos idiomas nem an√°lise sem√¢ntica profunda (ex: infer√™ncia de causas indiretas).
- A solu√ß√£o depende da qualidade da recupera√ß√£o: se o BM25 n√£o recuperar bons documentos, a gera√ß√£o ser√° menos precisa.
- Ainda n√£o foi feita a avalia√ß√£o quantitativa (ex: ROUGE, BLEU ou similaridade) da qualidade das respostas ‚Äî apenas qualitativa.

## üí° Exemplos de Perguntas de Teste

1. What caused the accident during takeoff?
2. Were there any fatalities in the accident near Texas?
3. What was the weather like during the crash in New Mexico?
4. Did pilot error contribute to the accident in Florida?
5. what cause the accident in vero beach accident?
6. What was the probable cause of the accident on May 30, 2023?
7. How severe were the injuries reported in the New Mexico accident?
8. Were there any accidents during night flights?
9. Did any accidents involve mechanical failure?
10. What was the probable cause of the accident with most causalities?
